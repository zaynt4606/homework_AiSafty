{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edf4930",
   "metadata": {},
   "source": [
    "# 利用CNN分类CIFAR-10数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e08c2",
   "metadata": {},
   "source": [
    "在该文档中，主要通过训练卷积神经网络来完成对CIFAR-10数据集进行图像分类。\n",
    "\n",
    "首先我的老电脑是没有GPU的，可以来看一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc15f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 检查是否可以利用GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.')\n",
    "else:\n",
    "    print('CUDA is available!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccc05c",
   "metadata": {},
   "source": [
    "因为贫穷的原因确实是not available，所以文档到此结束。\n",
    "咳咳，还试得硬着头皮搞的，时间太长跑不完就用co-lab嫖一下好了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b1b11",
   "metadata": {},
   "source": [
    "### 加载数据\n",
    "加载训练数据集，并且将数据分为训练集和测试集，再为每个数据集创建DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180526c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# 每批加载16张图片\n",
    "batch_size = 16\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# 将数据转换为torch.FloatTensor，并标准化。\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "# 选择训练集与测试集的数据\n",
    "train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10('data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# 图像分类中10类别\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e6e00",
   "metadata": {},
   "source": [
    "### 定义CNN结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a6cde19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义卷积神经网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 卷积层 (32x32x3的图像)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # 卷积层(16x16x16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # 卷积层(8x8x32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # 最大池化层\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        # dropout层 (p=0.3)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# 使用GPU\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc7979",
   "metadata": {},
   "source": [
    "### 选择损失函数与优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7065d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# 使用交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 使用随机梯度下降，学习率lr=0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423fdfaf",
   "metadata": {},
   "source": [
    "### 训练卷积神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48fdfff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\python\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.078950 \tValidation Loss: 1.758009\n",
      "Validation loss decreased (inf --> 1.758009).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 1.620644 \tValidation Loss: 1.498452\n",
      "Validation loss decreased (1.758009 --> 1.498452).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 1.451228 \tValidation Loss: 1.313831\n",
      "Validation loss decreased (1.498452 --> 1.313831).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 1.332905 \tValidation Loss: 1.222225\n",
      "Validation loss decreased (1.313831 --> 1.222225).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 1.230245 \tValidation Loss: 1.148164\n",
      "Validation loss decreased (1.222225 --> 1.148164).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 1.142225 \tValidation Loss: 1.068547\n",
      "Validation loss decreased (1.148164 --> 1.068547).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 1.067228 \tValidation Loss: 1.008666\n",
      "Validation loss decreased (1.068547 --> 1.008666).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 1.012903 \tValidation Loss: 0.939235\n",
      "Validation loss decreased (1.008666 --> 0.939235).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.954310 \tValidation Loss: 0.920974\n",
      "Validation loss decreased (0.939235 --> 0.920974).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.903835 \tValidation Loss: 0.923358\n",
      "Epoch: 11 \tTraining Loss: 0.867460 \tValidation Loss: 0.848017\n",
      "Validation loss decreased (0.920974 --> 0.848017).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.827535 \tValidation Loss: 0.818963\n",
      "Validation loss decreased (0.848017 --> 0.818963).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.791537 \tValidation Loss: 0.826229\n",
      "Epoch: 14 \tTraining Loss: 0.765741 \tValidation Loss: 0.812143\n",
      "Validation loss decreased (0.818963 --> 0.812143).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.733144 \tValidation Loss: 0.785563\n",
      "Validation loss decreased (0.812143 --> 0.785563).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.702631 \tValidation Loss: 0.760952\n",
      "Validation loss decreased (0.785563 --> 0.760952).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.675755 \tValidation Loss: 0.766690\n",
      "Epoch: 18 \tTraining Loss: 0.650206 \tValidation Loss: 0.763200\n",
      "Epoch: 19 \tTraining Loss: 0.628957 \tValidation Loss: 0.753950\n",
      "Validation loss decreased (0.760952 --> 0.753950).  Saving model ...\n",
      "Epoch: 20 \tTraining Loss: 0.603371 \tValidation Loss: 0.746298\n",
      "Validation loss decreased (0.753950 --> 0.746298).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.577675 \tValidation Loss: 0.760672\n",
      "Epoch: 22 \tTraining Loss: 0.560931 \tValidation Loss: 0.729024\n",
      "Validation loss decreased (0.746298 --> 0.729024).  Saving model ...\n",
      "Epoch: 23 \tTraining Loss: 0.534910 \tValidation Loss: 0.725528\n",
      "Validation loss decreased (0.729024 --> 0.725528).  Saving model ...\n",
      "Epoch: 24 \tTraining Loss: 0.518099 \tValidation Loss: 0.746252\n",
      "Epoch: 25 \tTraining Loss: 0.501059 \tValidation Loss: 0.731015\n",
      "Epoch: 26 \tTraining Loss: 0.484397 \tValidation Loss: 0.726336\n",
      "Epoch: 27 \tTraining Loss: 0.468918 \tValidation Loss: 0.753496\n",
      "Epoch: 28 \tTraining Loss: 0.449131 \tValidation Loss: 0.745466\n",
      "Epoch: 29 \tTraining Loss: 0.437546 \tValidation Loss: 0.726344\n",
      "Epoch: 30 \tTraining Loss: 0.423924 \tValidation Loss: 0.740021\n"
     ]
    }
   ],
   "source": [
    "# 训练模型的次数\n",
    "n_epochs = 30\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # 训练集的模型 #\n",
    "    ###################\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # 验证集的模型#\n",
    "    ######################\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # 计算平均损失\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    # 显示训练集与验证集的损失函数 \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # 如果验证集损失函数减少，就保存模型。\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700b32dd",
   "metadata": {},
   "source": [
    "### 测试训练好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce32824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.735211\n",
      "\n",
      "Test Accuracy of airplane: 80% (803/1000)\n",
      "Test Accuracy of automobile: 87% (878/1000)\n",
      "Test Accuracy of  bird: 68% (684/1000)\n",
      "Test Accuracy of   cat: 60% (600/1000)\n",
      "Test Accuracy of  deer: 69% (698/1000)\n",
      "Test Accuracy of   dog: 66% (660/1000)\n",
      "Test Accuracy of  frog: 83% (834/1000)\n",
      "Test Accuracy of horse: 76% (764/1000)\n",
      "Test Accuracy of  ship: 88% (880/1000)\n",
      "Test Accuracy of truck: 79% (790/1000)\n",
      "\n",
      "Test Accuracy (Overall): 75% (7591/10000)\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee3784",
   "metadata": {},
   "source": [
    "结果是75%的准确率，这样一个大概的简单的神经网络的训练模型就完成了，非常简洁，但是可以看到效果的的确确是有的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fac82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
